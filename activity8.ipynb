{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4e375db-003e-435a-bae7-7ec7c379513b",
   "metadata": {},
   "source": [
    "<h1>Crime GeoSpatial HeatMap: Chicago Crimes</h1>\n",
    "<h3>Inclusion Year: 2001-Present</h3>\n",
    "<h4>Analyst: Rogemson P. Molina</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbd0589-93d1-4a5d-9914-e395b49661f5",
   "metadata": {},
   "source": [
    "<h2> Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02a4066-3414-4263-95a4-35d60760c376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffc262a-0a43-4229-8793-f626f28ea441",
   "metadata": {},
   "source": [
    "<h2> Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cce90c-0617-4e44-8df5-61d55c0bf1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset//Chicago_Crimes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf94bb5-7dcf-4eaf-9a09-85f3e94a5817",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339bfcb0-5e51-4148-bb4f-bae8e1629dc4",
   "metadata": {},
   "source": [
    "<h2> Checking and filling up null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dc79d3-f25d-4714-8f1f-89a0811a6e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Location Description'] = df['Location Description'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c0d525-0efa-4605-89de-57aa8ce0e566",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eb5e05-6d84-4cc2-b70a-f3853c25290b",
   "metadata": {},
   "source": [
    "<h2> Changing datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820dd452-2cea-42f0-a874-f01ca251f8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caefb3c8-57af-4bc2-9f27-de04636b5127",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "df['Updated On'] = pd.to_datetime(df['Updated On'], errors='coerce')\n",
    "df['Community Area'] = df['Community Area'].fillna(-1).astype(int)\n",
    "df['Case Number'] = df['Case Number'].astype(str)\n",
    "df['IUCR'] = df['IUCR'].astype(str)\n",
    "df['Latitude'] = df['Latitude'].astype('float32')\n",
    "df['Longitude'] = df['Longitude'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8b1985-eb10-4cfd-934b-671fc42b0dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a274adf-e43b-47bd-a95c-9f36d04420ec",
   "metadata": {},
   "source": [
    "<h2> Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e981f6-861d-4874-97a6-7984da5c52d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Latitude', 'Longitude'])\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Month'] = df['Date'].dt.month_name()\n",
    "df['Day'] = df['Date'].dt.day_name()\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Hour'] = df['Date'].dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00ced37-6135-4ce7-946b-d840c7228734",
   "metadata": {},
   "source": [
    "<h3> Where are theft incidents most concentrated in the city?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd37dfb-1def-41d1-a243-e663cbe977a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[(df['Primary Type'] == 'THEFT') & df['Latitude'].notnull() & df['Longitude'].notnull()]\n",
    "\n",
    "print(f\"Filtered data size: {filtered_df.shape}\")\n",
    "\n",
    "aggregated_df = filtered_df.groupby(['Latitude', 'Longitude']).size().reset_index(name='incident_count')\n",
    "\n",
    "aggregated_df['normalized_weight'] = (\n",
    "    (aggregated_df['incident_count'] - aggregated_df['incident_count'].min()) /\n",
    "    (aggregated_df['incident_count'].max() - aggregated_df['incident_count'].min())\n",
    ")\n",
    "\n",
    "total_thefts = aggregated_df['incident_count'].sum()\n",
    "print(f\"Total number of theft incidents: {total_thefts}\")\n",
    "\n",
    "max_incident_location = aggregated_df.loc[aggregated_df['incident_count'].idxmax()]\n",
    "print(f\"Location with the highest number of theft incidents: Latitude {max_incident_location['Latitude']}, Longitude {max_incident_location['Longitude']}\")\n",
    "print(f\"Number of theft incidents in this location: {max_incident_location['incident_count']}\")\n",
    "\n",
    "heat_data = aggregated_df[['Latitude', 'Longitude', 'normalized_weight']].values.tolist()\n",
    "theft_map = folium.Map(location=[filtered_df['Latitude'].mean(), filtered_df['Longitude'].mean()], zoom_start=11)\n",
    "HeatMap(heat_data, radius=10, blur=15).add_to(theft_map)\n",
    "theft_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82b5689-5ebf-4c20-8ba9-72e1b088803b",
   "metadata": {},
   "source": [
    "<h2> Where are Assault cases concentrated the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a99969-0f50-4417-a5c3-ed3f116ea84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[(df['Primary Type'] == 'ASSAULT') & df['Latitude'].notnull() & df['Longitude'].notnull()]\n",
    "print(f\"Filtered data size: {filtered_df.shape}\")\n",
    "\n",
    "aggregated_df = filtered_df.groupby(['Latitude', 'Longitude']).size().reset_index(name='incident_count')\n",
    "aggregated_df['normalized_weight'] = (\n",
    "    (aggregated_df['incident_count'] - aggregated_df['incident_count'].min()) /\n",
    "    (aggregated_df['incident_count'].max() - aggregated_df['incident_count'].min())\n",
    ")\n",
    "\n",
    "total_assaults = aggregated_df['incident_count'].sum()\n",
    "print(f\"Total number of assault incidents: {total_assaults}\")\n",
    "\n",
    "max_incident_location = aggregated_df.loc[aggregated_df['incident_count'].idxmax()]\n",
    "print(f\"Location with the highest number of assault incidents: Latitude {max_incident_location['Latitude']}, Longitude {max_incident_location['Longitude']}\")\n",
    "print(f\"Number of assault incidents in this location: {max_incident_location['incident_count']}\")\n",
    "\n",
    "heat_data = aggregated_df[['Latitude', 'Longitude', 'normalized_weight']].values.tolist()\n",
    "\n",
    "assault_map = folium.Map(location=[filtered_df['Latitude'].mean(), filtered_df['Longitude'].mean()], zoom_start=11)\n",
    "HeatMap(heat_data, radius=10, blur=15).add_to(assault_map)\n",
    "assault_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defc420f-f678-4b6b-ac7d-bc5fa7ebf584",
   "metadata": {},
   "source": [
    "<h2> How do crime incidents vary with Domestic vs Non-Domestic crimes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa62d026-9701-40e8-9bb2-0fcef6ee017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[df['Domestic'] == True & df['Latitude'].notnull() & df['Longitude'].notnull()]\n",
    "\n",
    "print(f\"Filtered data size: {filtered_df.shape}\")\n",
    "\n",
    "aggregated_df = filtered_df.groupby(['Latitude', 'Longitude']).size().reset_index(name='incident_count')\n",
    "\n",
    "aggregated_df['normalized_weight'] = (\n",
    "    (aggregated_df['incident_count'] - aggregated_df['incident_count'].min()) /\n",
    "    (aggregated_df['incident_count'].max() - aggregated_df['incident_count'].min())\n",
    ")\n",
    "\n",
    "total_domestic_incidents = aggregated_df['incident_count'].sum()\n",
    "print(f\"Total number of domestic incidents: {total_domestic_incidents}\")\n",
    "\n",
    "max_incident_location = aggregated_df.loc[aggregated_df['incident_count'].idxmax()]\n",
    "print(f\"Location with the highest number of domestic incidents: Latitude {max_incident_location['Latitude']}, Longitude {max_incident_location['Longitude']}\")\n",
    "print(f\"Number of domestic incidents in this location: {max_incident_location['incident_count']}\")\n",
    "\n",
    "heat_data = aggregated_df[['Latitude', 'Longitude', 'normalized_weight']].values.tolist()\n",
    "domestic_map = folium.Map(location=[filtered_df['Latitude'].mean(), filtered_df['Longitude'].mean()], zoom_start=11)\n",
    "HeatMap(heat_data, radius=10, blur=15).add_to(domestic_map)\n",
    "domestic_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d304de-936a-4e96-b820-34a0bb8720d1",
   "metadata": {},
   "source": [
    "<h2> What is the relationship between crime type and the district?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb94ad0-2e5f-4471-8cb7-626363a648e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[(df['Primary Type'] == 'THEFT') & df['District'].notnull() & df['Latitude'].notnull() & df['Longitude'].notnull()]\n",
    "\n",
    "print(f\"Filtered data size: {filtered_df.shape}\")\n",
    "\n",
    "aggregated_df = filtered_df.groupby(['Latitude', 'Longitude', 'District']).size().reset_index(name='incident_count')\n",
    "\n",
    "aggregated_df['normalized_weight'] = (\n",
    "    (aggregated_df['incident_count'] - aggregated_df['incident_count'].min()) /\n",
    "    (aggregated_df['incident_count'].max() - aggregated_df['incident_count'].min())\n",
    ")\n",
    "\n",
    "total_theft_incidents = aggregated_df['incident_count'].sum()\n",
    "total_theft_answer = f\"Across the dataset, there were a total of {total_theft_incidents} theft incidents recorded.\"\n",
    "\n",
    "max_incident_location = aggregated_df.loc[aggregated_df['incident_count'].idxmax()]\n",
    "max_incident_answer = f\"The location with the highest number of theft incidents is at Latitude {max_incident_location['Latitude']}, Longitude {max_incident_location['Longitude']}, with {max_incident_location['incident_count']} incidents.\"\n",
    "\n",
    "print(total_theft_answer)\n",
    "print(max_incident_answer)\n",
    "\n",
    "heat_data = aggregated_df[['Latitude', 'Longitude', 'normalized_weight']].values.tolist()\n",
    "district_map = folium.Map(location=[filtered_df['Latitude'].mean(), filtered_df['Longitude'].mean()], zoom_start=11)\n",
    "HeatMap(heat_data, radius=10, blur=15).add_to(district_map)\n",
    "district_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b348c77-ba83-4153-b3a0-603f50930e1e",
   "metadata": {},
   "source": [
    "<h2> Crime frequency in different wards based on domestic violence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13df96c-2e2c-4e47-975a-7645b9bd9d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[(df['Domestic'] == True) & df['Ward'].isin([3, 7, 10]) & df['Latitude'].notnull() & df['Longitude'].notnull()]\n",
    "\n",
    "print(f\"Filtered data size: {filtered_df.shape}\")\n",
    "\n",
    "aggregated_df = filtered_df.groupby(['Latitude', 'Longitude']).size().reset_index(name='incident_count')\n",
    "\n",
    "aggregated_df['normalized_weight'] = (\n",
    "    (aggregated_df['incident_count'] - aggregated_df['incident_count'].min()) /\n",
    "    (aggregated_df['incident_count'].max() - aggregated_df['incident_count'].min())\n",
    ")\n",
    "\n",
    "total_domestic_incidents = aggregated_df['incident_count'].sum()\n",
    "total_domestic_answer = f\"Across the dataset, there were a total of {total_domestic_incidents} domestic violence incidents recorded in wards 3, 7, and 10.\"\n",
    "\n",
    "max_incident_location = aggregated_df.loc[aggregated_df['incident_count'].idxmax()]\n",
    "max_incident_answer = f\"The location with the highest number of domestic violence incidents is at Latitude {max_incident_location['Latitude']}, Longitude {max_incident_location['Longitude']}, with {max_incident_location['incident_count']} incidents.\"\n",
    "\n",
    "print(total_domestic_answer)\n",
    "print(max_incident_answer)\n",
    "\n",
    "heat_data = aggregated_df[['Latitude', 'Longitude', 'normalized_weight']].values.tolist()\n",
    "ward_map = folium.Map(location=[filtered_df['Latitude'].mean(), filtered_df['Longitude'].mean()], zoom_start=11)\n",
    "HeatMap(heat_data, radius=10, blur=15).add_to(ward_map)\n",
    "ward_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c5d2a3-d1d0-4ed1-9c7c-2bb8b662154a",
   "metadata": {},
   "source": [
    "<h2> Domestic Violence by Beat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bd9c99-db39-4dc5-842b-763241c35aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[(df['Domestic'] == True) & df['Beat'].notnull() & df['Latitude'].notnull() & df['Longitude'].notnull()]\n",
    "\n",
    "print(f\"Filtered data size: {filtered_df.shape}\")\n",
    "\n",
    "aggregated_df = filtered_df.groupby(['Latitude', 'Longitude', 'Beat']).size().reset_index(name='incident_count')\n",
    "\n",
    "aggregated_df['normalized_weight'] = (\n",
    "    (aggregated_df['incident_count'] - aggregated_df['incident_count'].min()) /\n",
    "    (aggregated_df['incident_count'].max() - aggregated_df['incident_count'].min())\n",
    ")\n",
    "\n",
    "total_domestic_incidents = aggregated_df['incident_count'].sum()\n",
    "total_domestic_answer = f\"Across the dataset, there were a total of {total_domestic_incidents} domestic violence incidents recorded by Beat.\"\n",
    "\n",
    "print(total_domestic_answer)\n",
    "\n",
    "heat_data = aggregated_df[['Latitude', 'Longitude', 'normalized_weight']].values.tolist()\n",
    "beat_map = folium.Map(location=[filtered_df['Latitude'].mean(), filtered_df['Longitude'].mean()], zoom_start=11)\n",
    "HeatMap(heat_data, radius=10, blur=15).add_to(beat_map)\n",
    "beat_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f376ca-33db-4341-add2-0d8689babc62",
   "metadata": {},
   "source": [
    "<h2> Crime Type vs. Arrest Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4d464f-f517-4bd2-b502-62dad7e4e9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[(df['Arrest'] == True) & df['Primary Type'].isin(['THEFT', 'ASSAULT']) & df['Latitude'].notnull() & df['Longitude'].notnull()]\n",
    "\n",
    "print(f\"Filtered data size: {filtered_df.shape}\")\n",
    "\n",
    "aggregated_df = filtered_df.groupby(['Latitude', 'Longitude', 'Primary Type']).size().reset_index(name='incident_count')\n",
    "\n",
    "aggregated_df['normalized_weight'] = (\n",
    "    (aggregated_df['incident_count'] - aggregated_df['incident_count'].min()) /\n",
    "    (aggregated_df['incident_count'].max() - aggregated_df['incident_count'].min())\n",
    ")\n",
    "total_arrested_incidents = aggregated_df['incident_count'].sum()\n",
    "total_arrested_answer = f\"Across the dataset, there were a total of {total_arrested_incidents} incidents resulting in arrest.\"\n",
    "\n",
    "print(total_arrested_answer)\n",
    "\n",
    "heat_data = aggregated_df[['Latitude', 'Longitude', 'normalized_weight']].values.tolist()\n",
    "arrest_map = folium.Map(location=[filtered_df['Latitude'].mean(), filtered_df['Longitude'].mean()], zoom_start=11)\n",
    "HeatMap(heat_data, radius=10, blur=15).add_to(arrest_map)\n",
    "arrest_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36aad5f-8c7d-4658-aa03-da6cadbb5bf0",
   "metadata": {},
   "source": [
    "<h2> Yearly Distribution of Crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764f0367-d73c-4539-aafc-396ced49e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[(df['Year'] >= 2015) & df['Primary Type'].isin(['THEFT', 'ASSAULT']) & df['Latitude'].notnull() & df['Longitude'].notnull()]\n",
    "\n",
    "print(f\"Filtered data size: {filtered_df.shape}\")\n",
    "\n",
    "aggregated_df = filtered_df.groupby(['Latitude', 'Longitude', 'Year']).size().reset_index(name='incident_count')\n",
    "\n",
    "aggregated_df['normalized_weight'] = (\n",
    "    (aggregated_df['incident_count'] - aggregated_df['incident_count'].min()) /\n",
    "    (aggregated_df['incident_count'].max() - aggregated_df['incident_count'].min())\n",
    ")\n",
    "\n",
    "total_crimes_2015_2020 = aggregated_df['incident_count'].sum()\n",
    "total_crimes_answer = f\"Across the dataset from 2015 to 2020, there were a total of {total_crimes_2015_2020} incidents.\"\n",
    "\n",
    "print(total_crimes_answer)\n",
    "\n",
    "heat_data = aggregated_df[['Latitude', 'Longitude', 'normalized_weight']].values.tolist()\n",
    "year_map = folium.Map(location=[filtered_df['Latitude'].mean(), filtered_df['Longitude'].mean()], zoom_start=11)\n",
    "HeatMap(heat_data, radius=10, blur=15).add_to(year_map)\n",
    "year_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787cc057-1d7b-4a54-8061-83e2ed354205",
   "metadata": {},
   "source": [
    "<h2> Crime by Community Area and Domestic Violence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc184592-a760-4aef-9b47-7551067ef498",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[(df['Domestic'] == True) & df['Community Area'].isin([1, 3, 5]) & df['Latitude'].notnull() & df['Longitude'].notnull()]\n",
    "\n",
    "print(f\"Filtered data size: {filtered_df.shape}\")\n",
    "\n",
    "aggregated_df = filtered_df.groupby(['Latitude', 'Longitude', 'Community Area']).size().reset_index(name='incident_count')\n",
    "\n",
    "aggregated_df['normalized_weight'] = (\n",
    "    (aggregated_df['incident_count'] - aggregated_df['incident_count'].min()) /\n",
    "    (aggregated_df['incident_count'].max() - aggregated_df['incident_count'].min())\n",
    ")\n",
    "\n",
    "total_domestic_incidents = aggregated_df['incident_count'].sum()\n",
    "total_domestic_answer = f\"Across the dataset, there were a total of {total_domestic_incidents} domestic violence incidents in the selected community areas.\"\n",
    "\n",
    "print(total_domestic_answer)\n",
    "\n",
    "heat_data = aggregated_df[['Latitude', 'Longitude', 'normalized_weight']].values.tolist()\n",
    "community_map = folium.Map(location=[filtered_df['Latitude'].mean(), filtered_df['Longitude'].mean()], zoom_start=11)\n",
    "HeatMap(heat_data, radius=10, blur=15).add_to(community_map)\n",
    "community_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd53095e-b565-4aa2-8af5-5c4ba682a1d6",
   "metadata": {},
   "source": [
    "<h2> Crime Description vs. Location Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15ba01a-cc68-4d91-bab9-c1c5cf5942ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[(df['Description'].notnull()) & df['Location Description'].notnull() & df['Latitude'].notnull() & df['Longitude'].notnull()]\n",
    "\n",
    "print(f\"Filtered data size: {filtered_df.shape}\")\n",
    "\n",
    "aggregated_df = filtered_df.groupby(['Latitude', 'Longitude', 'Description', 'Location Description']).size().reset_index(name='incident_count')\n",
    "\n",
    "aggregated_df['normalized_weight'] = (\n",
    "    (aggregated_df['incident_count'] - aggregated_df['incident_count'].min()) /\n",
    "    (aggregated_df['incident_count'].max() - aggregated_df['incident_count'].min())\n",
    ")\n",
    "total_crimes_description_location = aggregated_df['incident_count'].sum()\n",
    "total_crimes_description_location_answer = f\"Across the dataset, there were a total of {total_crimes_description_location} incidents with the given descriptions and locations.\"\n",
    "\n",
    "print(total_crimes_description_location_answer)\n",
    "\n",
    "heat_data = aggregated_df[['Latitude', 'Longitude', 'normalized_weight']].values.tolist()\n",
    "description_location_map = folium.Map(location=[filtered_df['Latitude'].mean(), filtered_df['Longitude'].mean()], zoom_start=11)\n",
    "HeatMap(heat_data, radius=10, blur=15).add_to(description_location_map)\n",
    "description_location_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833158f1-695f-4060-9f8c-23b986ce7be3",
   "metadata": {},
   "source": [
    "<h2> Crime Frequency by District and Year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b6a852-0a2e-469c-9be1-65e2ba97e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[(df['Year'] >= 2010) & df['District'].notnull() & df['Latitude'].notnull() & df['Longitude'].notnull()]\n",
    "\n",
    "print(f\"Filtered data size: {filtered_df.shape}\")\n",
    "\n",
    "aggregated_df = filtered_df.groupby(['Latitude', 'Longitude', 'District', 'Year']).size().reset_index(name='incident_count')\n",
    "\n",
    "aggregated_df['normalized_weight'] = (\n",
    "    (aggregated_df['incident_count'] - aggregated_df['incident_count'].min()) /\n",
    "    (aggregated_df['incident_count'].max() - aggregated_df['incident_count'].min())\n",
    ")\n",
    "\n",
    "total_crimes_by_district = aggregated_df['incident_count'].sum()\n",
    "total_crimes_answer = f\"Across the dataset, there were a total of {total_crimes_by_district} crimes recorded in the selected districts during the given period.\"\n",
    "\n",
    "print(total_crimes_answer)\n",
    "\n",
    "heat_data = aggregated_df[['Latitude', 'Longitude', 'normalized_weight']].values.tolist()\n",
    "district_year_map = folium.Map(location=[filtered_df['Latitude'].mean(), filtered_df['Longitude'].mean()], zoom_start=11)\n",
    "HeatMap(heat_data, radius=10, blur=15).add_to(district_year_map)\n",
    "district_year_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ba14be-9eaf-4242-9b1d-08fdad922ae9",
   "metadata": {},
   "source": [
    "<h2> Crime Frequency by Arrest and Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d581fb-1fcd-40a0-9c1d-8dac71c662f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[(df['Arrest'] == True) & df['Year'] >= 2015 & df['Latitude'].notnull() & df['Longitude'].notnull()]\n",
    "\n",
    "print(f\"Filtered data size: {filtered_df.shape}\")\n",
    "\n",
    "aggregated_df = filtered_df.groupby(['Latitude', 'Longitude', 'Year']).size().reset_index(name='incident_count')\n",
    "\n",
    "aggregated_df['normalized_weight'] = (\n",
    "    (aggregated_df['incident_count'] - aggregated_df['incident_count'].min()) /\n",
    "    (aggregated_df['incident_count'].max() - aggregated_df['incident_count'].min())\n",
    ")\n",
    "\n",
    "total_arrested_crimes_by_year = aggregated_df['incident_count'].sum()\n",
    "total_arrested_crimes_answer = f\"Across the dataset, there were a total of {total_arrested_crimes_by_year} arrested crimes between the years 2015 and the present.\"\n",
    "\n",
    "print(total_arrested_crimes_answer)\n",
    "\n",
    "heat_data = aggregated_df[['Latitude', 'Longitude', 'normalized_weight']].values.tolist()\n",
    "arrest_year_map = folium.Map(location=[filtered_df['Latitude'].mean(), filtered_df['Longitude'].mean()], zoom_start=11)\n",
    "HeatMap(heat_data, radius=10, blur=15).add_to(arrest_year_map)\n",
    "arrest_year_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99526487-7f99-4e69-a0e5-4195ed326ada",
   "metadata": {},
   "source": [
    "<h2> Theft Incidents in Apartments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31910606-7bf4-40e2-8663-3f4ac639adcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[(df['Primary Type'] == 'THEFT') & (df['Location Description'] == 'APARTMENT') & \n",
    "                 df['Latitude'].notnull() & df['Longitude'].notnull()]\n",
    "\n",
    "print(f\"Filtered data size: {filtered_df.shape}\")\n",
    "\n",
    "aggregated_df = filtered_df.groupby(['Latitude', 'Longitude']).size().reset_index(name='incident_count')\n",
    "aggregated_df['normalized_weight'] = (\n",
    "    (aggregated_df['incident_count'] - aggregated_df['incident_count'].min()) /\n",
    "    (aggregated_df['incident_count'].max() - aggregated_df['incident_count'].min())\n",
    ")\n",
    "\n",
    "total_thefts_in_apartments = aggregated_df['incident_count'].sum()\n",
    "total_thefts_answer = f\"Across the dataset, there were a total of {total_thefts_in_apartments} theft incidents reported in apartments.\"\n",
    "\n",
    "print(total_thefts_answer)\n",
    "\n",
    "heat_data = aggregated_df[['Latitude', 'Longitude', 'normalized_weight']].values.tolist()\n",
    "theft_apartment_map = folium.Map(location=[filtered_df['Latitude'].mean(), filtered_df['Longitude'].mean()], zoom_start=12)\n",
    "HeatMap(heat_data, radius=10, blur=15).add_to(theft_apartment_map)\n",
    "theft_apartment_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafa2156-bc34-47dc-b966-3d2c6ca8651e",
   "metadata": {},
   "source": [
    "<h2> Top 5 months with highest crime recorded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd8a13b-ed4a-4e3f-943a-8d48634b02f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_incidents = df.groupby('Month').size().reset_index(name='incident_count')\n",
    "\n",
    "top_5_months = monthly_incidents.sort_values(by='incident_count', ascending=False).head(5)\n",
    "\n",
    "print(top_5_months)\n",
    "\n",
    "filtered_df = df[df['Month'].isin(top_5_months['Month']) & df['Latitude'].notnull() & df['Longitude'].notnull()]\n",
    "\n",
    "aggregated_df = filtered_df.groupby(['Latitude', 'Longitude', 'Month']).size().reset_index(name='incident_count')\n",
    "\n",
    "aggregated_df['normalized_weight'] = (\n",
    "    (aggregated_df['incident_count'] - aggregated_df['incident_count'].min()) /\n",
    "    (aggregated_df['incident_count'].max() - aggregated_df['incident_count'].min())\n",
    ")\n",
    "\n",
    "heat_data = aggregated_df[['Latitude', 'Longitude', 'normalized_weight']].values.tolist()\n",
    "incident_map = folium.Map(location=[filtered_df['Latitude'].mean(), filtered_df['Longitude'].mean()], zoom_start=12)\n",
    "HeatMap(heat_data, radius=10, blur=15).add_to(incident_map)\n",
    "incident_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1bcd99-2661-4ea1-9149-bbbaf31e668e",
   "metadata": {},
   "source": [
    "<h2> Seasonal Crime Patterns — Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe8c4ea-5806-4e42-afaf-ec3cefd129d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_incidents = df.groupby('Day').size().reset_index(name='incident_count')\n",
    "top_5_days = daily_incidents.sort_values(by='incident_count', ascending=False).head(5)\n",
    "print(top_5_days)\n",
    "\n",
    "filtered_df = df[df['Day'].isin(top_5_days['Day']) & df['Latitude'].notnull() & df['Longitude'].notnull()]\n",
    "print(f\"Filtered data size: {filtered_df.shape}\")\n",
    "\n",
    "aggregated_df = filtered_df.groupby(['Latitude', 'Longitude', 'Day']).size().reset_index(name='incident_count')\n",
    "aggregated_df['normalized_weight'] = (\n",
    "    (aggregated_df['incident_count'] - aggregated_df['incident_count'].min()) /\n",
    "    (aggregated_df['incident_count'].max() - aggregated_df['incident_count'].min())\n",
    ")\n",
    "\n",
    "max_loc = aggregated_df.loc[aggregated_df['normalized_weight'].idxmax()]\n",
    "print(f\"Peak day location at Latitude {max_loc['Latitude']}, Longitude {max_loc['Longitude']}.\")\n",
    "print(f\"Total incidents on those days: {aggregated_df['incident_count'].sum()}.\")\n",
    "\n",
    "heat_data = aggregated_df[['Latitude', 'Longitude', 'normalized_weight']].values.tolist()\n",
    "seasonal_crime = folium.Map(location=[filtered_df['Latitude'].mean(), filtered_df['Longitude'].mean()], zoom_start=11)\n",
    "HeatMap(heat_data, radius=10, blur=15).add_to(seasonal_crime)\n",
    "seasonal_crime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88069341-55e1-4f0a-a1d6-013991a08797",
   "metadata": {},
   "source": [
    "<h2>  Most Arrested Crime Types at Night (8 PM – 4 AM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff40525-3d98-424c-a213-2fa334e3cc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "night_df = df[(df['Hour'].between(20, 23)) | (df['Hour'].between(0, 4)) & (df['Arrest'] == True)]\n",
    "crime_arrest_counts = night_df.groupby('Primary Type').size().reset_index(name='arrest_count')\n",
    "top_5_crimes = crime_arrest_counts.sort_values(by='arrest_count', ascending=False).head(5)\n",
    "print(top_5_crimes)\n",
    "\n",
    "filtered_df = night_df[night_df['Primary Type'].isin(top_5_crimes['Primary Type']) & \n",
    "                       night_df['Latitude'].notnull() & \n",
    "                       night_df['Longitude'].notnull()]\n",
    "print(f\"Filtered data size: {filtered_df.shape}\")\n",
    "\n",
    "aggregated_df = filtered_df.groupby(['Latitude', 'Longitude', 'Primary Type']).size().reset_index(name='arrest_count')\n",
    "aggregated_df['normalized_weight'] = (\n",
    "    (aggregated_df['arrest_count'] - aggregated_df['arrest_count'].min()) /\n",
    "    (aggregated_df['arrest_count'].max() - aggregated_df['arrest_count'].min())\n",
    ")\n",
    "\n",
    "max_loc = aggregated_df.loc[aggregated_df['normalized_weight'].idxmax()]\n",
    "print(f\"Peak arrest location at night: {max_loc['Latitude']}, {max_loc['Longitude']}\")\n",
    "print(f\"Total nighttime arrests: {aggregated_df['arrest_count'].sum()}.\")\n",
    "\n",
    "heat_data = aggregated_df[['Latitude', 'Longitude', 'normalized_weight']].values.tolist()\n",
    "crime_night = folium.Map(location=[filtered_df['Latitude'].mean(), filtered_df['Longitude'].mean()], zoom_start=11)\n",
    "HeatMap(heat_data, radius=10, blur=15).add_to(crime_night)\n",
    "crime_night"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec40c6a7-5e4d-4e36-bc24-b2c6a85474ec",
   "metadata": {},
   "source": [
    "<h2> Domestic Incidents in Residences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7853a51-41f1-47e3-a58e-b16e84e1d1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "domestic_df = df[(df['Domestic'] == True) & (df['Location Description'] == 'RESIDENCE')]\n",
    "domestic_count = domestic_df.groupby('Day').size().reset_index(name='incident_count')\n",
    "top_days = domestic_count.sort_values(by='incident_count', ascending=False).head(5)\n",
    "print(top_days)\n",
    "\n",
    "filtered_df = domestic_df[domestic_df['Day'].isin(top_days['Day']) & \n",
    "                          domestic_df['Latitude'].notnull() & \n",
    "                          domestic_df['Longitude'].notnull()]\n",
    "print(f\"Filtered data size: {filtered_df.shape}\")\n",
    "\n",
    "aggregated_df = filtered_df.groupby(['Latitude', 'Longitude', 'Day']).size().reset_index(name='incident_count')\n",
    "aggregated_df['normalized_weight'] = (\n",
    "    (aggregated_df['incident_count'] - aggregated_df['incident_count'].min()) /\n",
    "    (aggregated_df['incident_count'].max() - aggregated_df['incident_count'].min())\n",
    ")\n",
    "\n",
    "max_loc = aggregated_df.loc[aggregated_df['normalized_weight'].idxmax()]\n",
    "print(f\"Domestic peak at Latitude {max_loc['Latitude']}, Longitude {max_loc['Longitude']}\")\n",
    "print(f\"Total incidents: {aggregated_df['incident_count'].sum()}\")\n",
    "\n",
    "heat_data = aggregated_df[['Latitude', 'Longitude', 'normalized_weight']].values.tolist()\n",
    "domestice_residence = folium.Map(location=[filtered_df['Latitude'].mean(), filtered_df['Longitude'].mean()], zoom_start=11)\n",
    "HeatMap(heat_data, radius=10, blur=15).add_to(domestice_residence)\n",
    "domestice_residence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73acd8fb-7d9a-4e19-85c7-a02a06ef1192",
   "metadata": {},
   "source": [
    "<h2> Theft/Narcotics in Top 5 Community Areas on Weekdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be0ba04-8bfc-464e-8ddd-442c629c3498",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_df = df[df['Day'].isin(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday'])]\n",
    "target_crimes = weekday_df[weekday_df['Primary Type'].isin(['THEFT', 'NARCOTICS'])]\n",
    "\n",
    "top_areas = target_crimes['Community Area'].value_counts().head(5).index.tolist()\n",
    "filtered_df = target_crimes[target_crimes['Community Area'].isin(top_areas) & \n",
    "                            target_crimes['Hour'].between(12, 18) &\n",
    "                            target_crimes['Latitude'].notnull() & \n",
    "                            target_crimes['Longitude'].notnull()]\n",
    "print(f\"Filtered data size: {filtered_df.shape}\")\n",
    "\n",
    "aggregated_df = filtered_df.groupby(['Latitude', 'Longitude', 'Community Area']).size().reset_index(name='incident_count')\n",
    "aggregated_df['normalized_weight'] = (\n",
    "    (aggregated_df['incident_count'] - aggregated_df['incident_count'].min()) /\n",
    "    (aggregated_df['incident_count'].max() - aggregated_df['incident_count'].min())\n",
    ")\n",
    "\n",
    "max_loc = aggregated_df.loc[aggregated_df['normalized_weight'].idxmax()]\n",
    "print(f\"Peak weekday afternoon hotspot: {max_loc['Latitude']}, {max_loc['Longitude']}\")\n",
    "print(f\"Total weekday drug/theft cases: {aggregated_df['incident_count'].sum()}\")\n",
    "\n",
    "heat_data = aggregated_df[['Latitude', 'Longitude', 'normalized_weight']].values.tolist()\n",
    "theft_narcotics = folium.Map(location=[filtered_df['Latitude'].mean(), filtered_df['Longitude'].mean()], zoom_start=11)\n",
    "HeatMap(heat_data, radius=10, blur=15).add_to(theft_narcotics)\n",
    "theft_narcotics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a92c85-d3d5-41f3-9da5-1c9748b8e331",
   "metadata": {},
   "source": [
    "<h2> Criminal Damage in High-Numbered Wards with Reporting Delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c70f3d-68e7-4544-8cf8-42cb383ffb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Reporting Delay'] = (df['Updated On'] - df['Date']).dt.days\n",
    "\n",
    "damage_df = df[(df['Primary Type'] == 'CRIMINAL DAMAGE') & (df['Ward'] > 30)]\n",
    "high_delay_df = damage_df[damage_df['Reporting Delay'] > damage_df['Reporting Delay'].median()]\n",
    "print(f\"Delayed reports: {high_delay_df.shape}\")\n",
    "\n",
    "filtered_df = high_delay_df[high_delay_df['Latitude'].notnull() & high_delay_df['Longitude'].notnull()]\n",
    "aggregated_df = filtered_df.groupby(['Latitude', 'Longitude']).size().reset_index(name='incident_count')\n",
    "aggregated_df['normalized_weight'] = (\n",
    "    (aggregated_df['incident_count'] - aggregated_df['incident_count'].min()) /\n",
    "    (aggregated_df['incident_count'].max() - aggregated_df['incident_count'].min())\n",
    ")\n",
    "\n",
    "max_loc = aggregated_df.loc[aggregated_df['normalized_weight'].idxmax()]\n",
    "print(f\"Peak delay damage hotspot: {max_loc['Latitude']}, {max_loc['Longitude']}\")\n",
    "print(f\"Total delayed damage reports: {aggregated_df['incident_count'].sum()}\")\n",
    "\n",
    "heat_data = aggregated_df[['Latitude', 'Longitude', 'normalized_weight']].values.tolist()\n",
    "high_numbered_wards = folium.Map(location=[filtered_df['Latitude'].mean(), filtered_df['Longitude'].mean()], zoom_start=11)\n",
    "HeatMap(heat_data, radius=10, blur=15).add_to(high_numbered_wards)\n",
    "high_numbered_wards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228aa45e-cccf-4e60-902e-a8e38212e352",
   "metadata": {},
   "source": [
    "<h2> Crime Classification Comparison Based on Primary Type, FBI Code, and IUCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830c0f56-6f6d-4126-9009-7a73b6ccd6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_class_df = df[\n",
    "    (df['Primary Type'].isin(['THEFT', 'BATTERY', 'CRIMINAL DAMAGE'])) &\n",
    "    (df['FBI Code'].notnull()) & (df['IUCR'].notnull())\n",
    "]\n",
    "\n",
    "combo_counts = filtered_class_df.groupby(['Primary Type', 'FBI Code', 'IUCR']).size().reset_index(name='incident_count')\n",
    "high_freq_combos = combo_counts[combo_counts['incident_count'] > combo_counts['incident_count'].median()]\n",
    "print(f\"High frequency classification combinations: {high_freq_combos.shape}\")\n",
    "\n",
    "refined_df = df.merge(high_freq_combos, on=['Primary Type', 'FBI Code', 'IUCR'])\n",
    "filtered_df = refined_df[refined_df['Latitude'].notnull() & refined_df['Longitude'].notnull()]\n",
    "print(f\"Filtered mapping data size: {filtered_df.shape}\")\n",
    "\n",
    "aggregated_df = filtered_df.groupby(['Latitude', 'Longitude']).size().reset_index(name='incident_count')\n",
    "aggregated_df['normalized_weight'] = (\n",
    "    (aggregated_df['incident_count'] - aggregated_df['incident_count'].min()) /\n",
    "    (aggregated_df['incident_count'].max() - aggregated_df['incident_count'].min())\n",
    ")\n",
    "\n",
    "max_loc = aggregated_df.loc[aggregated_df['normalized_weight'].idxmax()]\n",
    "print(f\"Classification hotspot: Latitude {max_loc['Latitude']}, Longitude {max_loc['Longitude']}\")\n",
    "print(f\"Total incidents in selected classification groups: {aggregated_df['incident_count'].sum()}\")\n",
    "\n",
    "heat_data = aggregated_df[['Latitude', 'Longitude', 'normalized_weight']].values.tolist()\n",
    "crime_classification = folium.Map(location=[filtered_df['Latitude'].mean(), filtered_df['Longitude'].mean()], zoom_start=11)\n",
    "HeatMap(heat_data, radius=10, blur=15).add_to(crime_classification)\n",
    "crime_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1e9a65-95dc-4c25-84a5-2a217247797c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
